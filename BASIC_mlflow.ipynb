{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10073148-226b-43ff-b638-3a0aeed6d04c",
   "metadata": {},
   "source": [
    "# Air Quality Assessment Dataset\n",
    "\n",
    "This dataset focuses on air quality assessment across various regions. It contains 5000 samples and captures critical environmental and demographic factors that influence pollution levels.\n",
    "https://www.kaggle.com/datasets/mujtabamatin/air-quality-and-pollution-assessment\n",
    "## Key Features:\n",
    "\n",
    "- **Temperature (°C)**: Average temperature of the region.\n",
    "- **Humidity (%)**: Relative humidity recorded in the region.\n",
    "- **PM2.5 Concentration (µg/m³)**: Fine particulate matter levels.\n",
    "- **PM10 Concentration (µg/m³)**: Coarse particulate matter levels.\n",
    "- **NO2 Concentration (ppb)**: Nitrogen dioxide levels.\n",
    "- **SO2 Concentration (ppb)**: Sulfur dioxide levels.\n",
    "- **CO Concentration (ppm)**: Carbon monoxide levels.\n",
    "- **Proximity to Industrial Areas (km)**: Distance to the nearest industrial zone.\n",
    "- **Population Density (people/km²)**: Number of people per square kilometer in the region.\n",
    "\n",
    "## Target Variable: Air Quality Levels\n",
    "\n",
    "- **Good**: Clean air with low pollution levels.\n",
    "- **Moderate**: Acceptable air quality but with some pollutants present.\n",
    "- **Poor**: Noticeable pollution that may cause health issues for sensitive groups.\n",
    "- **Hazardous**: Highly polluted air posing serious health risks to the population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654293ee-21f9-4bd3-957b-8114a899d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import logging\n",
    "import logging\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86839be-d898-40c2-bdae-2fd7acaed8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "      <th>Air Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>319</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3</td>\n",
       "      <td>75.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>611</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.2</td>\n",
       "      <td>619</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.1</td>\n",
       "      <td>551</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12.7</td>\n",
       "      <td>303</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  PM2.5  PM10   NO2   SO2    CO  \\\n",
       "0         29.8      59.1    5.2  17.9  18.9   9.2  1.72   \n",
       "1         28.3      75.6    2.3  12.2  30.8   9.7  1.64   \n",
       "2         23.1      74.7   26.7  33.8  24.4  12.6  1.63   \n",
       "3         27.1      39.1    6.1   6.3  13.5   5.3  1.15   \n",
       "4         26.5      70.7    6.9  16.0  21.9   5.6  1.01   \n",
       "\n",
       "   Proximity_to_Industrial_Areas  Population_Density Air Quality  \n",
       "0                            6.3                 319    Moderate  \n",
       "1                            6.0                 611    Moderate  \n",
       "2                            5.2                 619    Moderate  \n",
       "3                           11.1                 551        Good  \n",
       "4                           12.7                 303        Good  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('updated_pollution_dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead4945e-fa97-4971-8a16-38ce2172e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Temperature                    5000 non-null   float64\n",
      " 1   Humidity                       5000 non-null   float64\n",
      " 2   PM2.5                          5000 non-null   float64\n",
      " 3   PM10                           5000 non-null   float64\n",
      " 4   NO2                            5000 non-null   float64\n",
      " 5   SO2                            5000 non-null   float64\n",
      " 6   CO                             5000 non-null   float64\n",
      " 7   Proximity_to_Industrial_Areas  5000 non-null   float64\n",
      " 8   Population_Density             5000 non-null   int64  \n",
      " 9   Air Quality                    5000 non-null   object \n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca6665-d54b-42b6-8407-859574f113ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6df55-c06b-42ad-b357-c78c35f5c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a12084-78b3-4bcc-a79e-5c5467c0235f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598d6c02-8554-40ab-b725-b8b88f44de22",
   "metadata": {},
   "source": [
    "average parameter:\n",
    "'micro': Calculate metrics globally by counting the total true positives, false negatives, and false positives.\n",
    "'macro': Calculate metrics for each class, and take the unweighted mean.\n",
    "'weighted': Calculate metrics for each class and take the weighted mean by the number of true instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3070e42-9fcb-4096-94dc-692c00609290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230487ed-4f28-45d8-ab64-f2b04d805271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write in terminal\n",
    "!export MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01493266-7cb4-4f7b-b9a5-17deddf55270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35ef894-74db-45f8-9bbe-5ac3d2913a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mlflow-projects-example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mlflow-projects-example.py\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow.pyfunc\n",
    "import logging.config\n",
    "import mlflow.sklearn\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", default=\"./updated_pollution_dataset.csv\")\n",
    "    parser.add_argument(\"--early_stopping_rounds\", type=int, default=10)\n",
    "    parser.add_argument(\"--average\", choices=['micro', 'macro', 'weighted'], default='weighted')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def configure_logging():\n",
    "    \"\"\"Configure logging handlers and return a logger instance.\"\"\"\n",
    "    \n",
    "    if Path(\"logging.conf\").exists():\n",
    "        logging.config.fileConfig(\"logging.conf\")\n",
    "    else:\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[logging.StreamHandler(sys.stdout)],\n",
    "            level=logging.INFO,\n",
    "        )\n",
    "\n",
    "\n",
    "def prepare_data(data_path):\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        quality_mapping = {'Good': 0, 'Moderate': 1, 'Poor': 2, 'Hazardous': 3}\n",
    "        df['Air Quality'] = df['Air Quality'].apply(lambda x: quality_mapping[x])\n",
    "        # Convert Population_Density to float\n",
    "        df[\"Population_Density\"] =df[\"Population_Density\"].astype(float)\n",
    "\n",
    "        \n",
    "        logging.debug(f\"prepare_data called with data_path: {data_path}\")\n",
    "        return df  \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error preparing data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "def split_data(loaded_data):\n",
    "    logging.info(\"splitting data...\")\n",
    "    try:\n",
    "        X = loaded_data.drop(columns=['Air Quality'])\n",
    "        y = loaded_data['Air Quality']\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "        logging.debug(f\"shape of X_train : {X_train.shape}\")\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Missing required column: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error splitting data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def create_model(args):\n",
    "    # Initialize the model for multi-class classification\n",
    "    logging.info(\"creating model...\")\n",
    "    model = XGBClassifier(\n",
    "        objective='multi:softmax',  # For probabilistic predictions\n",
    "        num_class=4,                # Number of classes\n",
    "        eval_metric=['mlogloss','merror'],   # Suitable for multi-class classification\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=args.early_stopping_rounds\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, y_test, y_pred, args):\n",
    "    logging.info(\"The training finished successfully and its fitting to test dataset.\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "     # Precision and Recall\n",
    "    precision = precision_score(y_test, y_pred, average=args.average)\n",
    "    recall = recall_score(y_test, y_pred, average=args.average)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    logging.info(\"precision: %s\", precision)\n",
    "    logging.info(\"recall: %s\", recall)\n",
    "\n",
    "\n",
    "    return  accuracy,precision,recall\n",
    "\n",
    "\n",
    "def job_done(args):\n",
    "    df = prepare_data(args.data)\n",
    "    if df is None:\n",
    "        logging.error(\"Data preparation failed. Exiting the script.\")\n",
    "        raise RuntimeError(\"Data preparation failed. Please check the input file.\")\n",
    "\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = split_data(df)\n",
    "\n",
    "    mlflow.set_experiment(\"a-new-demo\")\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        #Log parameters and metrics together\n",
    "        params = {\n",
    "            \"data\": args.data,\n",
    "            \"early_stopping_rounds\": args.early_stopping_rounds,\n",
    "            \"average\": args.average\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Create and train the model\n",
    "        model = create_model(args)\n",
    "        trained_model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "        y_pred = trained_model.predict(X_test)\n",
    "\n",
    "        accuracy, precision, recall = evaluate_model(trained_model, y_test, y_pred, args)\n",
    "        \n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Corrected model input example\n",
    "        model_input = pd.DataFrame([{\n",
    "            \"Temperature\": 29.8,\n",
    "            \"Humidity\": 59.1,\n",
    "            \"PM2.5\": 5.2,\n",
    "            \"PM10\": 17.9,\n",
    "            \"NO2\": 18.9,\n",
    "            \"SO2\": 9.2,\n",
    "            \"CO\": 1.72,\n",
    "            \"Proximity_to_Industrial_Areas\": 6.3,\n",
    "            \"Population_Density\": 319.0,\n",
    "        }])\n",
    "\n",
    "        # Simulated model output\n",
    "        model_output = pd.DataFrame({\"Air Quality\": [0]})\n",
    "\n",
    "        # Infer signature\n",
    "        signature = infer_signature(model_input, model_output)\n",
    "\n",
    "        # Save locally using XGBoost's native format\n",
    "        \n",
    "        trained_model.save_model(\"xgboost_model.ubj\")  # or Save as JSON \n",
    "        \n",
    "        # Log with MLflow using XGBoost flavor\n",
    "        mlflow.xgboost.log_model(\n",
    "            trained_model,\n",
    "            artifact_path=\"air-quality-xgboost-model\",\n",
    "            signature=signature,\n",
    "            input_example=model_input\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_done(parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9369541e-61c7-4853-8866-78f227473139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/01/14 17:45:27 INFO mlflow.tracking.fluent: Experiment with name 'a-new-demo' does not exist. Creating a new experiment.\n",
      "Accuracy: 0.95\n",
      "Precision: 0.96\n",
      "Recall: 0.95\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       300\n",
      "           1       0.95      0.94      0.95       225\n",
      "           2       0.88      0.91      0.90       150\n",
      "           3       0.97      0.89      0.93        75\n",
      "\n",
      "    accuracy                           0.95       750\n",
      "   macro avg       0.95      0.94      0.94       750\n",
      "weighted avg       0.96      0.95      0.95       750\n",
      "\n",
      "/Users/gabriel/opt/anaconda3/envs/opensource/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/gabriel/opt/anaconda3/envs/opensource/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:45:28] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python mlflow-projects-example.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d3ca30-63f5-42e0-9ace-c9d81d8bb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run in terminal\n",
    "#!mlflow ui\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9617897a-5124-4c1a-80df-4d0ae40ae0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3</td>\n",
       "      <td>75.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.2</td>\n",
       "      <td>619.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.1</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12.7</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  PM2.5  PM10   NO2   SO2    CO  \\\n",
       "0         29.8      59.1    5.2  17.9  18.9   9.2  1.72   \n",
       "1         28.3      75.6    2.3  12.2  30.8   9.7  1.64   \n",
       "2         23.1      74.7   26.7  33.8  24.4  12.6  1.63   \n",
       "3         27.1      39.1    6.1   6.3  13.5   5.3  1.15   \n",
       "4         26.5      70.7    6.9  16.0  21.9   5.6  1.01   \n",
       "\n",
       "   Proximity_to_Industrial_Areas  Population_Density  \n",
       "0                            6.3               319.0  \n",
       "1                            6.0               611.0  \n",
       "2                            5.2               619.0  \n",
       "3                           11.1               551.0  \n",
       "4                           12.7               303.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df[:5].drop(columns = 'Air Quality')\n",
    "sample[\"Population_Density\"] =sample[\"Population_Density\"].astype(float)\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979501d8-aa64-45d6-bebf-1d2c6ed2e1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb65f66e-f89b-4ff4-ba2e-8403ffc9d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Moderate', 'Moderate', 'Moderate', 'Good', 'Good']\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "logged_model = 'runs:/54b7f4b988c04bc2b5b92fc6bfe44991/air-quality-xgboost-model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "predictions = loaded_model.predict(sample)\n",
    "reverse_quality_mapping = {0: 'Good', 1: 'Moderate', 2: 'Poor', 3: 'Hazardous'}\n",
    "readable_predictions = [reverse_quality_mapping[p] for p in predictions]\n",
    "print(readable_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac44b00-7375-4589-b6b3-0dbc2bc3a06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cce82d3-09a3-421a-9459-e9565b30b558",
   "metadata": {},
   "source": [
    "## Production Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e40e8-71d2-4458-be89-2eb4b4bebb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba26420-b086-4404-8230-a80c88e50a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from typing import Union, Dict, List\n",
    "import logging\n",
    "\n",
    "class Airquality_Detector(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self) -> None:\n",
    "        self.target_encoder = None\n",
    "        self.model = None\n",
    "        self.required_columns = [\n",
    "            \"Temperature\", \"Humidity\", \"PM2.5\", \"PM10\", \"NO2\", \"SO2\", \"CO\",\n",
    "            \"Proximity_to_Industrial_Areas\", \"Population_Density\"\n",
    "        ]\n",
    "\n",
    "    def load_context(self, context) -> None:\n",
    "        \"\"\"Load the target encoder and model from artifacts.\"\"\"\n",
    "        try:\n",
    "            self.target_encoder = joblib.load(context.artifacts[\"target_encoder\"])\n",
    "            self.model = XGBClassifier()\n",
    "            self.model.load_model(context.artifacts[\"model\"])\n",
    "            logging.info(\"Model and encoder loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading model context: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _validate_columns(self, data: pd.DataFrame) -> None:\n",
    "        \"\"\"Validate that all required columns are present.\"\"\"\n",
    "        missing_cols = set(self.required_columns) - set(data.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "    def _process_json_input(self, json_input: Union[str, Dict, List]) -> pd.DataFrame:\n",
    "        \"\"\"Convert JSON input to pandas DataFrame.\"\"\"\n",
    "        try:\n",
    "            # Handle string input\n",
    "            if isinstance(json_input, str):\n",
    "                data = json.loads(json_input)\n",
    "            else:\n",
    "                data = json_input\n",
    "\n",
    "            # Handle single record vs list of records\n",
    "            if isinstance(data, dict):\n",
    "                df = pd.DataFrame([data])\n",
    "            elif isinstance(data, list):\n",
    "                df = pd.DataFrame(data)\n",
    "            else:\n",
    "                raise ValueError(\"JSON input must be a dictionary or list of dictionaries\")\n",
    "\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error processing JSON input: {str(e)}\")\n",
    "\n",
    "    def _preprocess_input(self, data: Union[str, Dict, List, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"Preprocess input data regardless of format.\"\"\"\n",
    "        try:\n",
    "            # Convert input to DataFrame if it's not already\n",
    "            if not isinstance(data, pd.DataFrame):\n",
    "                data = self._process_json_input(data)\n",
    "\n",
    "            # Validate columns\n",
    "            self._validate_columns(data)\n",
    "\n",
    "            # Ensure correct column order\n",
    "            data = data[self.required_columns]\n",
    "\n",
    "            # Convert datatypes\n",
    "            data = data.astype({\n",
    "                \"Temperature\": float,\n",
    "                \"Humidity\": float,\n",
    "                \"PM2.5\": float,\n",
    "                \"PM10\": float,\n",
    "                \"NO2\": float,\n",
    "                \"SO2\": float,\n",
    "                \"CO\": float,\n",
    "                \"Proximity_to_Industrial_Areas\": float,\n",
    "                \"Population_Density\": float\n",
    "            })\n",
    "\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error preprocessing input: {str(e)}\")\n",
    "\n",
    "    def predict(self, context, model_input: Union[str, Dict, List, pd.DataFrame]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Make predictions on the input data.\n",
    "        \n",
    "        Args:\n",
    "            context: MLflow model context\n",
    "            model_input: Can be one of:\n",
    "                - pandas DataFrame\n",
    "                - JSON string\n",
    "                - Python dictionary\n",
    "                - List of dictionaries\n",
    "                \n",
    "        Returns:\n",
    "            List of predicted air quality categories\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Preprocess the input\n",
    "            processed_input = self._preprocess_input(model_input)\n",
    "            # Log input for debugging\n",
    "            logging.info(f\"Input for prediction:\\n{processed_input}\") \n",
    "            # Make predictions\n",
    "            predictions = self.model.predict(processed_input)\n",
    "            # Convert numerical predictions to readable categories\n",
    "            if self.target_encoder is not None:\n",
    "                predictions = self.target_encoder.inverse_transform(predictions)\n",
    "            # Log predictions for debugging\n",
    "            logging.debug(f\"Decoded predictions: {predictions}\")\n",
    "            return predictions.tolist()  # Convert numpy array to list \n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during prediction: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "173c2f77-fbc8-43ca-a9eb-06a86180cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mlflow-projects-example-production.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mlflow-projects-example-production.py\n",
    "\n",
    "# mlflow-projects-example-production.py\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow.pyfunc\n",
    "import logging.config\n",
    "import logging\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "from joblib import dump\n",
    "import sys\n",
    "import joblib\n",
    "from pathlib import Path  # Added missing import\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from inference import Airquality_Detector\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", default=\"./updated_pollution_dataset.csv\")\n",
    "    parser.add_argument(\"--early_stopping_rounds\", type=int, default=10)\n",
    "    parser.add_argument(\"--average\", choices=['micro', 'macro', 'weighted'], default='weighted')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def configure_logging():\n",
    "    \"\"\"Configure logging handlers and return a logger instance.\"\"\"\n",
    "    \n",
    "    if Path(\"logging.conf\").exists():\n",
    "        logging.config.fileConfig(\"logging.conf\")\n",
    "    else:\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[logging.StreamHandler(sys.stdout)],\n",
    "            level=logging.INFO,\n",
    "        )\n",
    "\n",
    "\n",
    "def prepare_data(data_path):\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        df.columns = df.columns.str.strip()  # Remove any whitespace from column names        \n",
    "        # Convert Population_Density to float\n",
    "        df[\"Population_Density\"] =df[\"Population_Density\"].astype(float)\n",
    "\n",
    "        logging.debug(f\"prepare_data called with data_path: {data_path}\")\n",
    "        return df  \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error preparing data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def split_data(loaded_data):\n",
    "    logging.info(\"splitting data...\")\n",
    "    \n",
    "    try:\n",
    "        X = loaded_data.drop(columns=['Air Quality'])\n",
    "        y = loaded_data['Air Quality']\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "        logging.debug(f\"shape of X_train : {X_train.shape}\")\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Missing required column: {e}\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error splitting data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def create_model(args):\n",
    "    # Initialize the model for multi-class classification\n",
    "    logging.info(\"creating model...\")\n",
    "    model = XGBClassifier(\n",
    "        objective='multi:softmax',  # For probabilistic predictions\n",
    "        num_class=4,                # Number of classes\n",
    "        eval_metric=['mlogloss','merror'],   # Suitable for multi-class classification\n",
    "        random_state=42,\n",
    "        early_stopping_rounds=args.early_stopping_rounds\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, y_test, y_pred, args):\n",
    "    logging.info(\"The training finished successfully and its fitting to test dataset.\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "     # Precision and Recall\n",
    "    precision = precision_score(y_test, y_pred, average=args.average)\n",
    "    recall = recall_score(y_test, y_pred, average=args.average)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    logging.info(\"precision: %s\", precision)\n",
    "    logging.info(\"recall: %s\", recall)\n",
    "\n",
    "\n",
    "    return  accuracy,precision,recall\n",
    "\n",
    "\n",
    "def job_done(args):\n",
    "    df = prepare_data(args.data)\n",
    "    if df is None:\n",
    "        logging.error(\"Data preparation failed. Exiting the script.\")\n",
    "        raise RuntimeError(\"Data preparation failed. Please check the input file.\")\n",
    "\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = split_data(df)\n",
    "    # Initialize LabelEncoder\n",
    "    target_encoder = LabelEncoder()  # Fixed variable name\n",
    "    y_train = target_encoder.fit_transform(y_train)  # Fixed variable name\n",
    "    y_test = target_encoder.transform(y_test)  # Fixed variable name\n",
    "    y_val = target_encoder.transform(y_val)  # Fixed variable name\n",
    "\n",
    "    joblib.dump(target_encoder, 'target_encoder.pkl')\n",
    "    \n",
    "    print(\"LabelEncoder saved to 'target_encoder.pkl'.\")\n",
    "\n",
    "    mlflow.set_experiment(\"mlflow-production-demo\")\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Log parameters and metrics together\n",
    "        params = {\n",
    "            \"data\": args.data,\n",
    "            \"early_stopping_rounds\": args.early_stopping_rounds,\n",
    "            \"average\": args.average\n",
    "        }\n",
    "        mlflow.log_params(params)\n",
    "        # Create and train the model\n",
    "        model = create_model(args)\n",
    "        trained_model = train_model(model, X_train, y_train, X_val, y_val)\n",
    "        y_pred = trained_model.predict(X_test)\n",
    "\n",
    "        accuracy, precision, recall = evaluate_model(trained_model, y_test, y_pred, args)\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        model_input = pd.DataFrame([{\n",
    "            \"Temperature\": 29.8,\n",
    "            \"Humidity\": 59.1,\n",
    "            \"PM2.5\": 5.2,\n",
    "            \"PM10\": 17.9,\n",
    "            \"NO2\": 18.9,\n",
    "            \"SO2\": 9.2,\n",
    "            \"CO\": 1.72,\n",
    "            \"Proximity_to_Industrial_Areas\": 6.3,\n",
    "            \"Population_Density\": 319.0,\n",
    "        }])\n",
    "\n",
    "        signature = infer_signature(model_input, trained_model.predict(model_input))  # Fixed signature inference\n",
    "        \n",
    "        trained_model.save_model('air_model.ubj')\n",
    "\n",
    "        air_quality = Airquality_Detector()\n",
    "        artifacts = {\n",
    "            \"target_encoder\": \"./target_encoder.pkl\",\n",
    "            \"model\": \"./air_model.ubj\"\n",
    "        }\n",
    "        \n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path='model',\n",
    "            conda_env=\"./conda.yaml\",\n",
    "            python_model=air_quality,\n",
    "            artifacts=artifacts,\n",
    "            signature = signature,\n",
    "            input_example = model_input,\n",
    "            registered_model_name=air_quality_model,\n",
    "        \n",
    "            \n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_done(parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254cadd-64bc-4643-8f8c-08600aab351b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259002be-7d0a-4888-a21e-dadb1a0a805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder saved to 'target_encoder.pkl'.\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.94\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       300\n",
      "           1       0.92      0.77      0.84        75\n",
      "           2       0.92      0.97      0.95       225\n",
      "           3       0.86      0.87      0.86       150\n",
      "\n",
      "    accuracy                           0.94       750\n",
      "   macro avg       0.92      0.90      0.91       750\n",
      "weighted avg       0.94      0.94      0.94       750\n",
      "\n",
      "Downloading artifacts: 100%|████████████████████| 1/1 [00:00<00:00, 3692.17it/s]\n",
      "Downloading artifacts: 100%|████████████████████| 1/1 [00:00<00:00, 1400.90it/s]\n",
      "🏃 View run powerful-lynx-783 at: http://127.0.0.1:5000/#/experiments/468274013418532110/runs/1faa06996ad94733a1904ff8ea9976e4\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/468274013418532110\n"
     ]
    }
   ],
   "source": [
    "!python mlflow-projects-example-production.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5c213f-6ea7-47d4-b22b-9f73ef740eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO2</th>\n",
       "      <th>SO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>Proximity_to_Industrial_Areas</th>\n",
       "      <th>Population_Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.3</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.3</td>\n",
       "      <td>75.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>6.0</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.1</td>\n",
       "      <td>74.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.2</td>\n",
       "      <td>619.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.1</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.5</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.01</td>\n",
       "      <td>12.7</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  PM2.5  PM10   NO2   SO2    CO  \\\n",
       "0         29.8      59.1    5.2  17.9  18.9   9.2  1.72   \n",
       "1         28.3      75.6    2.3  12.2  30.8   9.7  1.64   \n",
       "2         23.1      74.7   26.7  33.8  24.4  12.6  1.63   \n",
       "3         27.1      39.1    6.1   6.3  13.5   5.3  1.15   \n",
       "4         26.5      70.7    6.9  16.0  21.9   5.6  1.01   \n",
       "\n",
       "   Proximity_to_Industrial_Areas  Population_Density  \n",
       "0                            6.3               319.0  \n",
       "1                            6.0               611.0  \n",
       "2                            5.2               619.0  \n",
       "3                           11.1               551.0  \n",
       "4                           12.7               303.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Population_Density\"] =df[\"Population_Density\"].astype(float)\n",
    "sample = df[:5].drop(columns = 'Air Quality')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e85ee44-6c3d-4405-9882-77903b508390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!export MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\"\n",
    "# Set the MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# run  last line in terminal\n",
    "#use the model run and directory/folder housing the model\n",
    "# mlflow models serve -m runs:/f3747c220a0b4629a57dce74b58d0b7d/model -h 0.0.0.0 -p 8080 --no-conda\n",
    "# OR\n",
    "# mlflow models serve -m models:/air_quality_model/1 -h 0.0.0.0 -p 8080 --no-conda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d350d51f-0758-435f-b2d0-04d1604d1c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"Moderate\"]}"
     ]
    }
   ],
   "source": [
    "!curl -X POST http://0.0.0.0:8080/invocations \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\"inputs\": [{\"Temperature\": 29.8, \"Humidity\": 59.1, \"PM2.5\": 26.7, \"PM10\": 33.8, \"NO2\": 30.8, \"SO2\":9.2,\"CO\":1.72,\"Proximity_to_Industrial_Areas\":11.1,\"Population_Density\":551.0}]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae85b0f-77f2-4426-a888-43486d9dd6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
